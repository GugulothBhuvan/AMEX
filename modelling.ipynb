{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbc9d2f",
   "metadata": {},
   "source": [
    "# **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9a71d",
   "metadata": {},
   "source": [
    "### **Importing Libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29126301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (4.6.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (3.0.2)\n",
      "Requirement already satisfied: catboost in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (1.2.8)\n",
      "Requirement already satisfied: polars in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (1.31.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from lightgbm) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from catboost) (2.3.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from catboost) (6.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\bhuva\\appdata\\roaming\\python\\python313\\site-packages (from plotly->catboost) (1.45.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm xgboost catboost polars numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154928de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0ef49",
   "metadata": {},
   "source": [
    "### **Load final datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a21a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory set to: D:\\Case studies competitions\\Amex\\CSV\\final_data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = r\"D:\\Case studies competitions\\Amex\\CSV\\final_data\"\n",
    "print(f\"Data directory set to: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b4f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use os.path.join (recommended)\n",
    "train_path = os.path.join(DATA_DIR, \"final_train.parquet\")\n",
    "test_path = os.path.join(DATA_DIR, \"final_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dee8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from: D:\\Case studies competitions\\Amex\\CSV\\final_data\\final_train.parquet\n",
      "Loading test data from: D:\\Case studies competitions\\Amex\\CSV\\final_data\\final_test.parquet\n"
     ]
    }
   ],
   "source": [
    "# Check if files exist before loading\n",
    "if os.path.exists(train_path):\n",
    "    print(f\"Loading train data from: {train_path}\")\n",
    "    train = pl.read_parquet(train_path)\n",
    "else:\n",
    "    print(f\"Train file not found at: {train_path}\")\n",
    "\n",
    "if os.path.exists(test_path):\n",
    "    print(f\"Loading test data from: {test_path}\")\n",
    "    test = pl.read_parquet(test_path)\n",
    "else:\n",
    "    print(f\"Test file not found at: {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fad161",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"y\"\n",
    "X_train = train.drop(target_col)\n",
    "y_train = train[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732c2670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (616131, 223)\n",
      "Validation shape: (154033, 223)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "# 1. Keep only allowed dtypes: Float64, Int64, Int32, Boolean\n",
    "allowed_types = (pl.Float64, pl.Int64, pl.Int32, pl.Boolean)\n",
    "\n",
    "# 2. Filter out non-numeric, list, struct, or duration columns\n",
    "X_train_flat = X_train.select([\n",
    "    col for col, dtype in X_train.schema.items()\n",
    "    if isinstance(dtype, allowed_types)\n",
    "])\n",
    "\n",
    "# 3. Convert to NumPy (now it's small and safe)\n",
    "X_np = X_train_flat.to_numpy()\n",
    "y_np = y_train.to_numpy().ravel()\n",
    "\n",
    "# 4. Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_np, y_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: Print shape to confirm\n",
    "print(\"Train shape:\", X_tr.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d4a4c",
   "metadata": {},
   "source": [
    "#### **Confirming Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c19bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features Used: 725\n",
      "Sample Feature Columns: ['id4', 'id5', 'f1', 'f2', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Confirm the target column\n",
    "target_col = \"y\"\n",
    "\n",
    "# Step 2: Exclude ID columns and target from training features\n",
    "id_cols = [\"id1\", \"id2\", \"id3\"]  # Used for mapping predictions later\n",
    "excluded_cols = id_cols + [target_col]\n",
    "\n",
    "# Step 3: Select feature columns automatically\n",
    "feature_cols = [col for col in train.columns if col not in excluded_cols]\n",
    "\n",
    "print(f\"Total Features Used: {len(feature_cols)}\")\n",
    "print(\"Sample Feature Columns:\", feature_cols[:10])\n",
    "\n",
    "# Step 4: Prepare training inputs\n",
    "X_train_pl = train.select(feature_cols)\n",
    "y_train_pl = train.select([target_col])\n",
    "\n",
    "# Optional: save the IDs for later mapping\n",
    "id_df = train.select(id_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ddc75",
   "metadata": {},
   "source": [
    "#### **Setting up LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88017380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create LightGBM Dataset\n",
    "train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916f31b",
   "metadata": {},
   "source": [
    "#### **Feature group mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a002b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define field groups\n",
    "field_groups = {\n",
    "    \"user\": [\"id2\", \"f2\", \"f29\", \"f42\", \"f43\"],  # example user features\n",
    "    \"offer\": [\"id3\", \"f5\", \"f6\", \"f7\", \"f8\"],    # offer-related features\n",
    "    \"event\": [\"id10\", \"f11\", \"f12\"],             # interaction/event\n",
    "    \"time\": [\"id4\", \"id5\", \"id12_year\", \"id13_day\"],  # time info\n",
    "    \"behavior\": [\"f90\", \"f91\", \"f92\", \"f93\"],    # derived behavior\n",
    "    \"interaction\": [\"id2_id3_combo\", \"id2_id10_combo\", \"id3_id10_combo\"],  # combo encodings\n",
    "    \"conversion\": [\"conversion_ratio_user\", \"conversion_ratio_offer\"]     # conversion features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56a3e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟩 USER (5 features): ['id2', 'f2', 'f29', 'f42', 'f43']\n",
      "🟩 OFFER (5 features): ['id3', 'f5', 'f6', 'f7', 'f8']\n",
      "🟩 EVENT (3 features): ['id10', 'f11', 'f12']\n",
      "🟩 TIME (4 features): ['id4', 'id5', 'id12_year', 'id13_day']\n",
      "🟩 BEHAVIOR (3 features): ['f90', 'f91', 'f93']\n",
      "🟩 INTERACTION (3 features): ['id2_id3_combo', 'id2_id10_combo', 'id3_id10_combo']\n",
      "🟩 OTHER (705 features): ['id1', 'f1', 'f9', 'f10', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27']...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Map all features to a field\n",
    "all_feature_cols = [col for col in train.columns if col != \"y\"]\n",
    "\n",
    "feature_to_field = {}\n",
    "for field, features in field_groups.items():\n",
    "    for feat in features:\n",
    "        if feat in all_feature_cols:\n",
    "            feature_to_field[feat] = field\n",
    "\n",
    "# Step 3: Assign \"other\" to remaining ungrouped features\n",
    "for col in all_feature_cols:\n",
    "    if col not in feature_to_field:\n",
    "        feature_to_field[col] = \"other\"\n",
    "\n",
    "# Step 4: Group summary (optional print)\n",
    "from collections import defaultdict\n",
    "field_summary = defaultdict(list)\n",
    "for feat, field in feature_to_field.items():\n",
    "    field_summary[field].append(feat)\n",
    "\n",
    "for field, feats in field_summary.items():\n",
    "    print(f\"🟩 {field.upper()} ({len(feats)} features): {feats[:10]}{'...' if len(feats) > 10 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "750ea14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7df8554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Define columns to exclude (leakage-prone or non-numeric)\n",
    "leakage_cols = [\n",
    "    \"id1\", \"id2\", \"id3\", \"id10\", \"id12\", \"id13\", \"y\",\n",
    "    \"id2_id3_combo\", \"id2_id10_combo\", \"id3_id10_combo\",\n",
    "    \"conversion_ratio_user\", \"conversion_ratio_offer\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f5641e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Select numeric-only + safe features\n",
    "valid_cols = []\n",
    "for col, dtype in train.schema.items():\n",
    "    if col not in leakage_cols and isinstance(dtype, (pl.Float32, pl.Float64, pl.Int32, pl.Int64)):\n",
    "        valid_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5095d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Prepare features and labels\n",
    "X = train.select(valid_cols)\n",
    "y = train[\"y\"].to_numpy().ravel()\n",
    "X_np = X.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "169b4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Train/Validation Split\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(X_np, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f505b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 6: LightGBM Dataset\n",
    "lgb_train = lgb.Dataset(X_train_np, label=y_train_np)\n",
    "lgb_val = lgb.Dataset(X_val_np, label=y_val_np, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "509c5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: LightGBM Parameters\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4452d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Starting LightGBM training...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttrain's auc: 0.991589\tval's auc: 0.990221\n",
      "[40]\ttrain's auc: 0.992333\tval's auc: 0.990615\n",
      "[60]\ttrain's auc: 0.992998\tval's auc: 0.99094\n",
      "[80]\ttrain's auc: 0.993576\tval's auc: 0.991177\n",
      "[100]\ttrain's auc: 0.994101\tval's auc: 0.99131\n",
      "[120]\ttrain's auc: 0.994584\tval's auc: 0.991389\n",
      "[140]\ttrain's auc: 0.994931\tval's auc: 0.991451\n",
      "[160]\ttrain's auc: 0.995294\tval's auc: 0.991478\n",
      "[180]\ttrain's auc: 0.995654\tval's auc: 0.991542\n",
      "[200]\ttrain's auc: 0.996033\tval's auc: 0.991541\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttrain's auc: 0.995714\tval's auc: 0.991558\n",
      "✅ Training completed in 41.13 seconds\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Training\n",
    "print(\"⚙️ Starting LightGBM training...\")\n",
    "start = time.time()\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    num_boost_round=300,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=20),\n",
    "        log_evaluation(period=20)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"✅ Training completed in {time.time() - start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5a2b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_np = y_val_np.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb43cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluation Metrics on Validation Set:\n",
      "AUC:          0.99156\n",
      "Accuracy:     0.98341\n",
      "Precision:    0.88024\n",
      "Recall:       0.74862\n",
      "F1 Score:     0.80911\n",
      "Log Loss:     0.04319\n",
      "Confusion Matrix:\n",
      "[[146060    737]\n",
      " [  1819   5417]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, log_loss, confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "# Convert y_val to int if needed\n",
    "y_val_np = y_val_np.astype(int)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_pred_proba = model.predict(X_val_np)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"🔍 Evaluation Metrics on Validation Set:\")\n",
    "print(f\"AUC:          {roc_auc_score(y_val_np, y_pred_proba):.5f}\")\n",
    "print(f\"Accuracy:     {accuracy_score(y_val_np, y_pred):.5f}\")\n",
    "print(f\"Precision:    {precision_score(y_val_np, y_pred):.5f}\")\n",
    "print(f\"Recall:       {recall_score(y_val_np, y_pred):.5f}\")\n",
    "print(f\"F1 Score:     {f1_score(y_val_np, y_pred):.5f}\")\n",
    "print(f\"Log Loss:     {log_loss(y_val_np, y_pred_proba):.5f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_val_np, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad0246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
